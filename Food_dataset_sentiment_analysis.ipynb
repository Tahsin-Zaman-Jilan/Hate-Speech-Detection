{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7pTLQ0sijEa"
   },
   "source": [
    "# Sentiment Analysis with Natural Language Processing\n",
    "\n",
    "### **Natural Language Processing with TensorFlow:**\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/f7e2c4afbb6b72870b81cdd3b09fa6869c90f74753a2693ce90b911f9413c41e/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d7264626f75726b652f74656e736f72666c6f772d646565702d6c6561726e696e672f6d61696e2f696d616765732f30382d6578616d706c652d6e6c702d70726f626c656d732e706e67\"/>\n",
    "\n",
    "The main goal of [natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) is to derive information from natural language.\n",
    "\n",
    "Natural language is a broad term but you can consider it to cover any of the following:\n",
    "\n",
    "* Text (such as that contained in an email, blog post, book, Tweet)\n",
    "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
    "Under the umbrellas of text and speech there are many different things you might want to do.\n",
    "\n",
    "If you're building an email application, you might want to scan incoming emails to see if they're spam or not spam (classification).\n",
    "\n",
    "If you're trying to analyse customer feedback complaints, you might want to discover which section of your business they're for.\n",
    "\n",
    "### Topics covered:\n",
    "\n",
    "* Downloading the food data.\n",
    "* Visualizing the food related text data.\n",
    "* Converting the text into numbers using tokenization.\n",
    "* Turning our tokenized text into an embedding.\n",
    "* Modelling the food text dataset.\n",
    "  * Starting with a baseline model for comparison.\n",
    "  * Building several deep learning models.\n",
    "    * LSTM, GRU\n",
    "* Comparing the performance of each our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEuDKrSrj1be"
   },
   "source": [
    "### Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DZggv-2l8Q4",
    "outputId": "e660b13e-c221-491c-d8e0-3157145b8e7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vflHR5LWl93I"
   },
   "source": [
    "Importing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYa5vELvmCvf",
    "outputId": "94ce1cc1-a9d6-484c-9aaf-a589d4a80f21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download helper functions script\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Cf45SdRmFBA"
   },
   "outputs": [],
   "source": [
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imwKvggxmJAL"
   },
   "source": [
    "### Download the text dataset\n",
    "\n",
    "Let's start by downloading the dataset. We'll be using the [Datasets for natural language processing](https://www.kaggle.com/datasets/toygarr/datasets-for-natural-language-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG9mPoZinnSy"
   },
   "source": [
    "## Visualizing the food text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tMTd9pJXqiHZ",
    "outputId": "df2a5274-48ed-4353-e442-95425ef0b78a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3ceae00f-b8cc-4d4b-ae1e-59816cd99a0e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was put off at first by the green powder but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these ginger chews are too good to be true i t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love salt and use a variety of salts to keep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if asked to sum up this coffee pod drawer in o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>so far my dog has tried the chicken and peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ceae00f-b8cc-4d4b-ae1e-59816cd99a0e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3ceae00f-b8cc-4d4b-ae1e-59816cd99a0e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3ceae00f-b8cc-4d4b-ae1e-59816cd99a0e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  Y\n",
       "0  i was put off at first by the green powder but...  1\n",
       "1  these ginger chews are too good to be true i t...  1\n",
       "2  i love salt and use a variety of salts to keep...  1\n",
       "3  if asked to sum up this coffee pod drawer in o...  1\n",
       "4  so far my dog has tried the chicken and peanut...  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn .csv files into pandas DataFrame's\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"data/food/train.csv\")\n",
    "test_df = pd.read_csv(\"data/food/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QQ_GHI8trNmI",
    "outputId": "b8b8f84c-4333-43fa-b244-c1f2617984f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-69166b65-e116-471a-8591-21f49e72178b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>i am absolutely addicted to this tea i made th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200933</th>\n",
       "      <td>i was happy to find this vegan alternative to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119706</th>\n",
       "      <td>my maltese dogs loved these duck yams i purcha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90324</th>\n",
       "      <td>i have tried every indian sauce on the market ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193956</th>\n",
       "      <td>i have already written heinz and told them i l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69166b65-e116-471a-8591-21f49e72178b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-69166b65-e116-471a-8591-21f49e72178b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-69166b65-e116-471a-8591-21f49e72178b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  Y\n",
       "139408  i am absolutely addicted to this tea i made th...  1\n",
       "200933  i was happy to find this vegan alternative to ...  0\n",
       "119706  my maltese dogs loved these duck yams i purcha...  1\n",
       "90324   i have tried every indian sauce on the market ...  1\n",
       "193956  i have already written heinz and told them i l...  1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2G7k25VLrk8m"
   },
   "source": [
    "Notice how the training data has a \"Y\" column.\n",
    "\n",
    "We're going to be writing code to find patterns (e.g. different combinations of words) in the \"text\" column of the training dataset to predict the value of the \"Y\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4ojLM4lvrv6V",
    "outputId": "238ece03-d0c8-49cf-b0f9-b41e6eae939e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-adccca76-d9b0-4808-a21c-753a6694cb77\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the perfect blend of spice and sweet i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the only coffee shop in town that carried big ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this was a great price but amazon is not going...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>while i love this product i feel disappointed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have color treated hair and wanted to try th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adccca76-d9b0-4808-a21c-753a6694cb77')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-adccca76-d9b0-4808-a21c-753a6694cb77 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-adccca76-d9b0-4808-a21c-753a6694cb77');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  Y\n",
       "0  this is the perfect blend of spice and sweet i...  1\n",
       "1  the only coffee shop in town that carried big ...  1\n",
       "2  this was a great price but amazon is not going...  1\n",
       "3  while i love this product i feel disappointed ...  1\n",
       "4  i have color treated hair and wanted to try th...  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtwMGQQzr0Wl",
    "outputId": "12f36d90-53cd-4940-ae6d-05ec207f5c12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    183739\n",
       "0     34187\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "IXJw6Rjor5u9",
    "outputId": "bdff305f-fa9f-4469-9a42-c6fa87ebdfff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.countplot(train_df['Y'])\n",
    "g.set_xticklabels(['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T26gUOpttZDY"
   },
   "source": [
    "## This is an imbalanced dataset\n",
    "\n",
    "So, in order to balance the dataset we are going to apply random undersampaling to the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5MmfVPZt5xP"
   },
   "outputs": [],
   "source": [
    "Y_0 = train_df[train_df.Y == 0]\n",
    "Y_1 = train_df[train_df.Y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llhFcvD3uHqW",
    "outputId": "6d57fb77-473c-44a5-9ede-e5ffd017d876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34187, 2) (183739, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Y_0.shape, Y_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXr8pEKFuKK9"
   },
   "outputs": [],
   "source": [
    "Y_1_sample = Y_1.sample(n=34187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHyxuY4Wu8Kj"
   },
   "outputs": [],
   "source": [
    "train_df_under_sampled = pd.concat([Y_0, Y_1_sample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ce46-UVnvRzC",
    "outputId": "dcdc5fc1-70f8-456c-dab2-1b93d9aa8bc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-18b42774-29ca-4fbd-8690-d8a526e064fd\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i love the flower teasi purchase them often fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>this is a great and attentive company attends ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i do not mind subtle but i thought outside of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>while i have liked the other products in this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ordered dozen red roses and was assured delive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b42774-29ca-4fbd-8690-d8a526e064fd')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-18b42774-29ca-4fbd-8690-d8a526e064fd button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-18b42774-29ca-4fbd-8690-d8a526e064fd');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 text  Y\n",
       "23  i love the flower teasi purchase them often fr...  0\n",
       "27  this is a great and attentive company attends ...  0\n",
       "35  i do not mind subtle but i thought outside of ...  0\n",
       "37  while i have liked the other products in this ...  0\n",
       "38  ordered dozen red roses and was assured delive...  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_under_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "i-1mgM32vVyy",
    "outputId": "6f0d4076-2faa-4e44-81a5-2970dc77dc9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(train_df_under_sampled['Y'])\n",
    "g.set_xticklabels(['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcZNu_rwvaXS",
    "outputId": "2de5dbab-1114-4489-9baa-c5ecc244457e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 217926\n",
      "Total test samples: 145293\n",
      "Total samples: 363219\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0749RMxvgLZ",
    "outputId": "d78fb9c3-9669-42ab-e735-8e62f1116424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (positive)\n",
      "Text:\n",
      "i bought a couple of bags of french roast beans and i love it i grind my own very fine because i love a full bodied cup of coffee in fact i decided to buy more while it was on sale \n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (positive)\n",
      "Text:\n",
      "i discovered the knorr fix line of products about a year ago our family has been sampling them little by little and this is one of the standouts whether you like to pan fry your burger or grill em up this seasoning is the best we have ever tried we were lawrey is fans for years and still are but this beats them down no contest \n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (positive)\n",
      "Text:\n",
      "some people want to criticize organic products due to their often higher than average cost i am not sure i agree with that thinking organic ingredients are more expensive and their added cost ensures that you and your pets are eating food that meets strict production standards is it worth it well consider the source of the ingredients in most pet food i shudder to think about the junk that makes its way into food that you feed to your beloved animals that is why i am more than willing to seek out and pay more for quality in the form of products like newman is own organics lamb and barley new zealand ranch style dog treats what you get for your money is the peace of mind that comes from knowing that your dog will be eating human grade ingredients including certified organic barley flour ground chicken carrots apples rolled oats etc my beagle loves these treats and i love giving her food that keeps her healthy \n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (positive)\n",
      "Text:\n",
      "could not find this product in stores or jello web site amazon had it so glad they did this puddig taste like no other and is the best \n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (positive)\n",
      "Text:\n",
      "this bag has a lot of candy but the flavor choices are great the apple is juicy not tart the pomegranate is tangy the cherry is on the sweet side not too sour and the honey lemon is a great combination being organic is a plus \n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"Y\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, Y = row\n",
    "  print(f\"Target: {Y}\", \"(positive)\" if Y > 0 else \"(negative)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z6IehIlIwHTo",
    "outputId": "b917c4d7-94d2-4e2d-a5d9-956ab91bd627"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-37e750cc-7451-4aa7-84fd-36bfc4da2608\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>i had asked for mazipan for christmas and rece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136205</th>\n",
       "      <td>the same exact product is available directly f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137314</th>\n",
       "      <td>bought from mfs wholesale came melted and brok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113584</th>\n",
       "      <td>whole life freeze dried chicken is a little pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200743</th>\n",
       "      <td>delicious i was in publix yesterday and saw th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e750cc-7451-4aa7-84fd-36bfc4da2608')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-37e750cc-7451-4aa7-84fd-36bfc4da2608 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-37e750cc-7451-4aa7-84fd-36bfc4da2608');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  Y\n",
       "153141  i had asked for mazipan for christmas and rece...  0\n",
       "136205  the same exact product is available directly f...  1\n",
       "137314  bought from mfs wholesale came melted and brok...  0\n",
       "113584  whole life freeze dried chicken is a little pr...  1\n",
       "200743  delicious i was in publix yesterday and saw th...  1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled_under_sampled = train_df_under_sampled.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled_under_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBYCaAelxB9r"
   },
   "source": [
    "### Split data into training and validation sets\n",
    "\n",
    "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n",
    "\n",
    "We'll convert our splits from pandas Series datatypes to lists of strings (for the text) and lists of ints (for the labels) for ease of use later.\n",
    "\n",
    "To split our training dataset and create a validation dataset, we'll use Scikit-Learn's `train_test_split()` method and dedicate 10% of the training samples to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tri39crLxXfb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled_under_sampled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled_under_sampled[\"Y\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproduci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5es6mZDvxoo4",
    "outputId": "a41397d0-e3e2-486f-fd08-75027d50b513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61536, 61536, 6838, 6838)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PnS699fxqje",
    "outputId": "0bb7caed-e8b5-4e5e-994b-a74a8d6944cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['the noodles are great easy to cook and delicious just need more recipes to use them good purchase ',\n",
       "        'i tried wellness and evo but my puppy had loose stool so i studied and gave orijin puppy food my puppy is stool got worse and she refuse to eat orijin puppy food now i have changed to other brand dehydrated food addiction she likes it and seems working well so far maybe orijin was too much protein to her i liked orijin product so i was bit disappointed maybe when she gets bigger i may try adult orijin ',\n",
       "        'after being warned by another review that reported their shipment was missing items i took a chance anyway because my daughter really wanted a venus fly trap i figured that out of plants arriving was not bad for the price i was willing to pay since they were so highly desired out of three plants arrived as others had warned who knows what happened to the third plant because my daughter was thrilled with the two that did arrive i will leave this review to warn others but will not pursue it with the company the scarlet belle pitcher plant did not arrive ',\n",
       "        'i never thought i liked mojitos and maybe i do not but i really enjoyed the crystal light mocktails mojito flavor the color is a bit off putting it looks like flat tonic water doused with a serious hand of lime juice but the taste is very light and refreshing it is ever so slightly minty with a good lime flavor i liked this flavor a great deal and will be repurchasing in the future ',\n",
       "        'the product arrived very quickly and was exactly what we expected good job by cream of wheat instant maple brown sugar boxes pack of',\n",
       "        'very stale tasting may have been caused by shelf life also very bold strong not the great tasting k cup might be better off pick this up from your local store imo ',\n",
       "        'i have been ordering jasmine tea from various suppliers for a few years now i found this to be some of the best priced dragon pearl jasmine tea around the jasmine scent is definitely on the weak side i believe this is due to the number of times the tea is scented in addition the tea is shipped in a tin that is not vacuum packed over time the tea will lose its jasmine scent if it is not sealed properly i would recommend this tea if you are on a budget and you are an amazon prime member free shipping if you are a jasmine tea aficionado shop elsewhere i give stars for the price update after using this tea for a couple weeks now the jasmine scent has almost completely dissipated i have adjusted my rating to stars ',\n",
       "        'the blue crab bay co steaming spices are delicious for steamed shrimp could not find them nearby so had to order online awesome service and will do business again when these run out ',\n",
       "        'this is an arabica blend this coffee leaves a lot to be desired typical waiting room quality coffeegreat for the breakroom at work but i would not chose to drink this ',\n",
       "        'these noodles are easy and quick to prepare and supply long lasting energy for hours i personally eat about half a bag with butter and fish for breakfast at and feel satisfied until in the afternoon the only downside is splitting the contents in half you can break it apart but some of the dry noodles fall out so do it over the sink or outside '],\n",
       "       dtype=object), array([1, 0, 0, 1, 1, 0, 0, 1, 0, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBUwY2lIxuEN"
   },
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "Wonderful! We've got a training set and a validation set containing Tweets and labels.\n",
    "\n",
    "Our labels are in numerical form (`0` and `1`) but our Texts are in string form.\n",
    "\n",
    "In NLP, there are two main concepts for turning text into numbers:\n",
    "\n",
    "* Tokenization - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
    "  1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
    "  2. **Character-level tokenization**, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
    "  3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**.\n",
    "\n",
    "* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
    "  1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as `tf.keras.layers.Embedding`) and an embedding representation will be learned during model training.\n",
    "  2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e89-KNS-yytW"
   },
   "source": [
    "## Text vectorization (tokenization)\n",
    "\n",
    "To tokenize our words, we'll use the helpful preprocessing layer `tf.keras.layers.experimental.preprocessing.TextVectorization`.\n",
    "\n",
    "The TextVectorization layer takes the following parameters:\n",
    "\n",
    "`max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
    "`standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n",
    "`split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n",
    "`ngrams` - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n",
    "`output_mode` - How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), \"count\" or `\"tf-idf\"`. See documentation for more.\n",
    "`output_sequence_length` - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
    "`pad_to_max_tokens` - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than `max_tokens`. Only valid in certain modes, see docs for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K_9msF4zfA0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pizFIxzzj_s"
   },
   "source": [
    "We've initialized a TextVectorization object with the default settings but let's customize it a little bit for our own use case.\n",
    "\n",
    "In particular, let's set values for max_tokens and output_sequence_length.\n",
    "\n",
    "For max_tokens (the number of words in the vocabulary), multiples of 10,000 (10,000, 20,000, 30,000) or the exact number of unique words in your text (e.g. 32,179) are common values.\n",
    "\n",
    "For our use case, we'll use 10,000.\n",
    "\n",
    "And for the output_sequence_length we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB1alrvp0JCL",
    "outputId": "57d4c362-bd3a-4e63-ac41-4623c776686b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find average number of tokens (words) in training texts\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b6y-Kme0PA6"
   },
   "outputs": [],
   "source": [
    "max_vocab_length = 50000 # max number of words to have in our vocabulary\n",
    "max_length = 81 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xixKVKV60dRp"
   },
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZtESkxN0hLR",
    "outputId": "c6355683-6220-4aa4-8edb-47fda537a505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 81), dtype=int64, numpy=\n",
       "array([[ 7248,     5, 13866,    12,    15,  4072,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1FkxZqS0oQY",
    "outputId": "3e9e3947-b905-4058-a73d-3fc6c6da5a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "according to the tracking info the package was delivered but i never received it i reached out to customer service they dismissed me and offered no assistance including refusing to contact the postal service to file a claim thanks to amazon i was able to get my money back however as a first time customer i would expect some assistance and support       \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 81), dtype=int64, numpy=\n",
       "array([[ 1249,     7,     2,  3778,  1717,     2,   185,    17,   811,\n",
       "           18,     3,   129,   196,     6,     3,  4408,    56,     7,\n",
       "          543,   526,    22, 11434,    51,     4,  1143,    55,  8009,\n",
       "          824,  7084,     7,  1400,     2,  6939,   526,     7,  6152,\n",
       "            5,  1369,   615,     7,    72,     3,    17,   380,     7,\n",
       "           59,    15,   189,   146,   165,    24,     5,    99,    80,\n",
       "          543,     3,    34,   642,    68,  8009,     4,  2006,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3SSSlQ_0vPw",
    "outputId": "cf3a8503-ddf7-45f1-c726-1fa003397fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 48959\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'i', 'and']\n",
      "Bottom 5 least common words: ['aaaah', 'aaaaallll', 'aaaaaahhhhhyaaaaaa', 'aaaaaahhhhh', 'aaaaaa']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnpukmB31CGd"
   },
   "source": [
    "## Creating an Embedding using an Embedding Layer\n",
    "\n",
    "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
    "\n",
    "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. 1 = I, 2 = love, 3 = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
    "\n",
    "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
    "\n",
    "The main parameters we're concerned about here are:\n",
    "\n",
    "* input_dim - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
    "* output_dim - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
    "* embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
    "* input_length - Length of sequences being passed to embedding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1UbDQDe1X1m",
    "outputId": "e968333b-6a88-4084-d77c-0909a4f03c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f55a036a650>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vg28OW-h1gcW",
    "outputId": "543b1a74-d9b6-41c3-b94d-63615dc6284d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "i use this for homemade lemonade daily i make mine with the yellow sugar substitute but you can get the same thing for at costco if you are lucky enough to be near one       \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 81, 128), dtype=float32, numpy=\n",
       "array([[[-0.04284013, -0.01489798, -0.0159496 , ..., -0.01166106,\n",
       "          0.03061062,  0.01972148],\n",
       "        [-0.02213949, -0.03946913,  0.03560385, ...,  0.04807695,\n",
       "          0.01491269, -0.03690983],\n",
       "        [-0.02399485,  0.01468222,  0.00041829, ...,  0.02498427,\n",
       "         -0.02674054, -0.00808267],\n",
       "        ...,\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uqDK6ga1oMF",
    "outputId": "21fbea45-a085-4b0a-89af-9c1083e554ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.04284013, -0.01489798, -0.0159496 , -0.0226305 ,  0.04298959,\n",
       "       -0.04682324, -0.0026353 ,  0.01123267, -0.03430966, -0.00190909,\n",
       "        0.02867594,  0.0297017 ,  0.02498296,  0.00814937,  0.04493314,\n",
       "        0.04413916, -0.00577633,  0.03141482,  0.00966071, -0.04037346,\n",
       "        0.03765199, -0.01732815, -0.02747819, -0.02993454, -0.02981216,\n",
       "        0.0308927 , -0.02260027, -0.00124929,  0.01732543, -0.02180376,\n",
       "       -0.03130232, -0.04009864,  0.03664006, -0.01028627, -0.03222132,\n",
       "        0.00378202, -0.02535181, -0.00505129,  0.02522682, -0.01333591,\n",
       "        0.0391151 , -0.00091956,  0.02860123, -0.04375963,  0.01296742,\n",
       "        0.0263852 , -0.04896233, -0.04747603,  0.04653648,  0.01485529,\n",
       "       -0.04613405,  0.00209745, -0.00271541,  0.03082445,  0.04200928,\n",
       "       -0.04887832, -0.04972835, -0.0254328 ,  0.03892423, -0.02046248,\n",
       "       -0.0439718 , -0.0345499 , -0.0287706 ,  0.03040506,  0.03975679,\n",
       "        0.0200902 , -0.04209707,  0.03103017, -0.02071968, -0.00967366,\n",
       "       -0.02754457,  0.04369733,  0.01162106,  0.01392407, -0.04973647,\n",
       "       -0.01128978,  0.03097404, -0.03560804, -0.01036394,  0.01256882,\n",
       "        0.02780786, -0.00832926, -0.00847365, -0.03672216,  0.02708429,\n",
       "       -0.03837278,  0.02184938, -0.03841377, -0.0183001 , -0.0102418 ,\n",
       "        0.01095847,  0.0250273 , -0.01542648, -0.01772868, -0.0121302 ,\n",
       "        0.04175656,  0.0218983 ,  0.00327895,  0.02876614,  0.0470233 ,\n",
       "       -0.02171609,  0.03210327, -0.03597981,  0.04386485, -0.02587393,\n",
       "       -0.02878708,  0.00671787, -0.01140868, -0.01845489,  0.00401658,\n",
       "        0.01123898,  0.0443519 , -0.01752155, -0.01664012, -0.01706991,\n",
       "        0.02205701, -0.00104143,  0.039237  , -0.03086319, -0.01964866,\n",
       "       -0.00477686, -0.00302611,  0.0110452 , -0.02808467, -0.0259782 ,\n",
       "       -0.01166106,  0.03061062,  0.01972148], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqHgrMvV1qyt"
   },
   "source": [
    "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
    "\n",
    "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYOQ742K1821",
    "outputId": "8c268e97-e948-485b-b571-c4881160d87c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQdL3LU519YU",
    "outputId": "4d7b38c7-93c0-41e0-faf9-52cda1cde9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 87.06%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IubIDG92CGE",
    "outputId": "8883e743-21ed-4e41-834b-962d50700d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGOzE9yk2Gfs"
   },
   "source": [
    "## Creating an evaluation function for our model experiments\n",
    "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
    "\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    ">  Note: Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1FKHUrw2WLr"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajb5O7eg2YsT",
    "outputId": "ad0bb1ec-5e4d-4f3e-bec9-741fd8779a8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 87.05761918689674,\n",
       " 'f1': 0.8705758015899729,\n",
       " 'precision': 0.8706576729400801,\n",
       " 'recall': 0.8705761918689675}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvdY8dYA2aX7"
   },
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n",
    "\n",
    "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
    "\n",
    "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
    "\n",
    "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog.\n",
    "\n",
    "See what happened there?\n",
    "\n",
    "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
    "\n",
    "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
    "\n",
    "For a simple example, take two sentences:\n",
    "\n",
    "1. Massive earthquake last week, no?\n",
    "2. No massive earthquake last week.\n",
    "\n",
    "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
    "\n",
    "Recurrent neural networks can be used for a number of sequence-based problems:\n",
    "\n",
    "* One to one: one input, one output, such as image classification.\n",
    "* One to many: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
    "* Many to one: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
    "* Many to many: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
    "\n",
    "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
    "\n",
    "* Long short-term memory cells (LSTMs).\n",
    "* Gated recurrent units (GRUs).\n",
    "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
    "\n",
    "Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences.\n",
    "\n",
    "For a deeper understanding of what's happening behind the scenes of the code we're about to write, I'd recommend the following resources:\n",
    "\n",
    "> Resources:\n",
    "  * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n",
    "  * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
    "  * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr-wY_8g21-5"
   },
   "source": [
    "## Model 1: LSTM\n",
    "\n",
    "With all this talk of what RNN's are and what they're good for, I'm sure you're eager to build one.\n",
    "\n",
    "We're going to start with an LSTM-powered RNN.\n",
    "\n",
    "To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use `tensorflow.keras.layers.LSTM()`.\n",
    "\n",
    "nput (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
    "\n",
    "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
    "\n",
    "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (model_1_embedding) for our model. The text_vectorizer layer can be reused since it doesn't get updated during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xW7Xk_ZA3NQg",
    "outputId": "64e3a0ce-0703-4108-87c3-a3eaeeb21dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 81, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_1_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_1\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_1_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiaUjGFj3caY"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKPAcFtY3jdH",
    "outputId": "188139c2-8c76-4c1b-c4a9-26d420570085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_2 (TextV  (None, 81)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 81, 128)           6400000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,449,473\n",
      "Trainable params: 6,449,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIt7op543n_3",
    "outputId": "f3e1181d-8c54-4320-fe55-cea4cae30b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20220806-111734\n",
      "Epoch 1/5\n",
      "1923/1923 [==============================] - 28s 11ms/step - loss: 0.6323 - accuracy: 0.6475 - val_loss: 0.6324 - val_accuracy: 0.6271\n",
      "Epoch 2/5\n",
      "1923/1923 [==============================] - 21s 11ms/step - loss: 0.4467 - accuracy: 0.7870 - val_loss: 0.3233 - val_accuracy: 0.8641\n",
      "Epoch 3/5\n",
      "1923/1923 [==============================] - 21s 11ms/step - loss: 0.2374 - accuracy: 0.9058 - val_loss: 0.2849 - val_accuracy: 0.8836\n",
      "Epoch 4/5\n",
      "1923/1923 [==============================] - 20s 10ms/step - loss: 0.1642 - accuracy: 0.9380 - val_loss: 0.2946 - val_accuracy: 0.8834\n",
      "Epoch 5/5\n",
      "1923/1923 [==============================] - 21s 11ms/step - loss: 0.1155 - accuracy: 0.9592 - val_loss: 0.3585 - val_accuracy: 0.8736\n"
     ]
    }
   ],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\"\n",
    "\n",
    "# Fit model\n",
    "\n",
    "model_1_history = model_1.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsIuc7RX3--G",
    "outputId": "c00e2ea2-1f30-429d-ac24-5d712ab5d76a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6838, 1), array([[0.981998  ],\n",
       "        [0.994418  ],\n",
       "        [0.99846184],\n",
       "        [0.05309127],\n",
       "        [0.00378915],\n",
       "        [0.00191134],\n",
       "        [0.99744487],\n",
       "        [0.00857504],\n",
       "        [0.00796135],\n",
       "        [0.98579454]], dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape, model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvVn5xxP46Bb",
    "outputId": "27cd26a6-b361-4515-d59f-c926ef0006c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 0., 1., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EC_qbOA54-1V",
    "outputId": "5cf399cd-bec3-46fd-a32e-89f4fb2ed6db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 87.36472652822462,\n",
       " 'f1': 0.8736484759131308,\n",
       " 'precision': 0.8736592529261012,\n",
       " 'recall': 0.8736472652822462}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwHvhwA75PZZ",
    "outputId": "28dd8f22-8dbd-4ac6-e46f-494171d81acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 87.06, New accuracy: 87.36, Difference: 0.31\n",
      "Baseline precision: 0.87, New precision: 0.87, Difference: 0.00\n",
      "Baseline recall: 0.87, New recall: 0.87, Difference: 0.00\n",
      "Baseline f1: 0.87, New f1: 0.87, Difference: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYLwXh_J5EPC",
    "outputId": "5261c55e-81d3-4993-b395-88d4200cee4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 87.06, New accuracy: 87.36, Difference: 0.31\n",
      "Baseline precision: 0.87, New precision: 0.87, Difference: 0.00\n",
      "Baseline recall: 0.87, New recall: 0.87, Difference: 0.00\n",
      "Baseline f1: 0.87, New f1: 0.87, Difference: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ly58k9TZ5HAK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Food_dataset_sentiment_analysis.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
